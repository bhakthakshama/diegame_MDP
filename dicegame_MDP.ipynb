{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Consider the following game:\n",
        "\n",
        "In each round you choose to stay or quit. If you quit, you get 100 Rupees and we end the game. If you decide to stay, you get 40 Rupees and you roll a die. If the die shows up 1 or 2, the game ends. Otherwise it continues.\n",
        "\n",
        "Simulate the game for different policies (that is, what action you take among stay/quit), generate the reward sequence.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "gupT2CKv77ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "plt.style.use('dark_background')\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "KSZTAh_Ghbdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class for the die game Markov Decision Process (MDP)\n",
        "class DieGameMDP() :\n",
        "\n",
        "  def __init__ (self) :\n",
        "    # state space of the MDP\n",
        "    self.states = [0, 1] # list of states : 0 = in the game and 1 = out of the game\n",
        "\n",
        "  # starting state of the MDP\n",
        "  def startState (self) :\n",
        "    return (self.states [0])\n",
        "\n",
        "  # check if the MDP has ended\n",
        "  def isEnd (self, state) :\n",
        "    return (state == self.states [1]) # return true meaning you are out of the game\n",
        "\n",
        "  # possible actions from a given state\n",
        "  def actions (self, state) :\n",
        "    action_list = []\n",
        "    action_list.append ('stay')\n",
        "    action_list.append('quit')\n",
        "    return (action_list)\n",
        "\n",
        "  # return the list of possible new states, the corresponding probabilities and the corresponding rewards\n",
        "  def NewStateProbReward (self, state, action) : # for the agent, what is the current state and what is the action\n",
        "    newStateProbReward_list = []\n",
        "    if action in self.actions (state) :\n",
        "      if state == self.states [0] :\n",
        "        if action == 'stay' :\n",
        "          newStateProbReward_list.append ((state, 2/3, 40))\n",
        "          newStateProbReward_list.append ((state + 1, 1/3, 40))\n",
        "        elif action == 'quit' :\n",
        "          newStateProbReward_list.append ((state + 1, 1, 100))\n",
        "      else :\n",
        "        newStateProbReward_list.append ((state, 1, 0)) # terminal state\n",
        "    return (newStateProbReward_list)\n",
        "\n",
        "  # reward discounting\n",
        "  def discount (self) : # (gamma itself)\n",
        "    return 0.95 # when made 0.9, discount will be applied"
      ],
      "metadata": {
        "id": "KlWvWekghsT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the dice game MDP object\n",
        "dieGameMDP = DieGameMDP ()"
      ],
      "metadata": {
        "id": "dA9EX5NOpZAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what are the possible actions available from state 0 which is the 'in' state?\n",
        "dieGameMDP.actions (0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fcwzwn9jpnbq",
        "outputId": "d95da693-0041-42e1-af38-80332bb71f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stay', 'quit']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what are the possible actions available from state 1 which is the 'out' state ?\n",
        "dieGameMDP.actions (1) # ALREADY OUT OF THE GAME SO NOTHING but coding is easier this way"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xygEcf2Mp05M",
        "outputId": "1979643a-b543-4641-ef6f-0a85ca7e7bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stay', 'quit']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# interpret what are the possible (new state, corresponding probability, corresponding reward)\n",
        "# available from state 0 (the 'in' state) and action 'stay'\n",
        "dieGameMDP.NewStateProbReward (0, 'stay')\n",
        "# can be in the game with prob 2/3 and reward 40 OR can be out of the game with prob 1/3 and reward 40"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU-8Ti10qGYZ",
        "outputId": "012add0e-498d-4939-b7e8-055d1acd51ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0.6666666666666666, 40), (1, 0.3333333333333333, 40)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dieGameMDP.NewStateProbReward (0, 'quit')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0oMqGhcr1_y",
        "outputId": "9643980c-daf3-406f-c045-57969f41afba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1, 100)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dieGameMDP.NewStateProbReward (1, 'stay')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziHixvnPr4m-",
        "outputId": "2d030911-6df4-4673-ac43-00927bb23633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1, 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dieGameMDP.NewStateProbReward (1, 'quit')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wsuu1mlZr9e2",
        "outputId": "69d47fb1-2c28-4840-adbe-2f690882098a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1, 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a deterministic policy (what action to take in a given state ?)\n",
        "# this case is always stay\n",
        "def policy1 (dieGameMDP, state) :\n",
        "  # return ('stay')\n",
        "  return (dieGameMDP.actions (state) [0])"
      ],
      "metadata": {
        "id": "Rw8LMH3msGhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.choice ([0, 1], size = 1, p = [2/3, 1/3]) # out of 100 approximately, 0 will show up 66 times and 1 will show up 34 times"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_ld-LOfzbaI",
        "outputId": "c0e44f66-e2ce-4fc7-a9a6-4ed579d2f93d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "range(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rdRjM9R1aId",
        "outputId": "e63ca999-7d03-4888-eac8-995e47799b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# deterministic policy\n",
        "def policy2 (dieGameMDP, state) :\n",
        "  return (dieGameMDP.actions (state) [1])"
      ],
      "metadata": {
        "id": "gm84lNf7YQlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# non deterministic policy\n",
        "def policy3 (dieGameMDP, state) :\n",
        "  return (np.random.choice (dieGameMDP.actions (0), size = 1, p = [0.8, 0.2]))"
      ],
      "metadata": {
        "id": "JvnTd3qDcrOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate the reward sequence using the policy\n",
        "G = 0 # cumulative reward intially 0\n",
        "k = 0 # represents the timestamp (power of gamma)\n",
        "state = dieGameMDP.startState () # start state\n",
        "\n",
        "while not dieGameMDP.isEnd (state) :\n",
        "\n",
        "  action = policy1 (dieGameMDP, state) # action to be taken at the current state\n",
        "  SPR_list = dieGameMDP.NewStateProbReward (state, action) # possible new states, corresponding probabilities and corresponding rewards\n",
        "  prob = [tuple[1] for tuple in SPR_list] # transition probabilities\n",
        "  index = np.random.choice(range (len (SPR_list)), size = 1, p = prob)[0]\n",
        "  newState = SPR_list [index][0] # new state\n",
        "  reward = SPR_list [index][2] # reward\n",
        "\n",
        "  print(f'Current State = {state}, Action = {action}, New State = {newState}, Reward = {reward}')\n",
        "\n",
        "  state = newState # update the state to new state\n",
        "  G = G + (dieGameMDP.discount ()) ** k * reward # update the cumulative reward\n",
        "  k = k + 1\n",
        "\n",
        "print(f'Net discounted Reward = {G}')"
      ],
      "metadata": {
        "id": "U5Z0SZ7WxXKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfdbc3b7-23d3-4b98-c00a-a80b06fc0e6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current State = 0, Action = stay, New State = 0, Reward = 40\n",
            "Current State = 0, Action = stay, New State = 1, Reward = 40\n",
            "Net discounted Reward = 78.0\n"
          ]
        }
      ]
    }
  ]
}